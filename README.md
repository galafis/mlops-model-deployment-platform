# MLOps Model Deployment Platform

![Python](https://img.shields.io/badge/Python-3.9%2B-blue?style=for-the-badge&logo=python&logoColor=white)
![Flask](https://img.shields.io/badge/Flask-2.3.x-black?style=for-the-badge&logo=flask&logoColor=white)
![Docker](https://img.shields.io/badge/Container-Docker-blue?style=for-the-badge&logo=docker&logoColor=white)
![Kubernetes](https://img.shields.io/badge/Orchestration-Kubernetes-blue?style=for-the-badge&logo=kubernetes&logoColor=white)
![Mermaid](https://img.shields.io/badge/Diagrams-Mermaid-orange?style=for-the-badge&logo=mermaid&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green.svg?style=for-the-badge)

---

## üáßüá∑ Plataforma de Deploy de Modelos MLOps

Este reposit√≥rio apresenta uma **plataforma completa para o deploy e gerenciamento de modelos de Machine Learning (ML) em produ√ß√£o**, seguindo as melhores pr√°ticas de MLOps. O foco √© em automatizar o ciclo de vida do modelo, desde o treinamento e versionamento at√© a implanta√ß√£o, monitoramento e retreinamento, garantindo **escalabilidade, confiabilidade e reprodutibilidade** em ambientes de produ√ß√£o.

### üéØ Objetivo

O principal objetivo deste projeto √© **fornecer um guia detalhado e exemplos de c√≥digo funcional** para engenheiros de ML, cientistas de dados e arquitetos que buscam construir ou otimizar suas pipelines de MLOps. Ser√£o abordados os conceitos fundamentais, ferramentas e tecnologias para criar uma plataforma robusta de deploy de modelos, com √™nfase em **versionamento de modelos, estrat√©gias de deployment avan√ßadas e uma API de infer√™ncia em tempo real**.

### ‚ú® Destaques

- **Versionamento de Modelos**: Implementa√ß√£o de um registro de modelos (`ModelRegistry`) que suporta versionamento (`ModelMetadata`), permitindo o gerenciamento de diferentes vers√µes de modelos e seus metadados associados.
- **Estrat√©gias de Deployment Avan√ßadas**: Suporte a diversas estrat√©gias de deployment, como **Blue/Green** e **Canary Releases**, para garantir transi√ß√µes seguras e controladas de modelos em produ√ß√£o, minimizando riscos e tempo de inatividade.
- **API de Infer√™ncia em Tempo Real (Flask)**: Uma API RESTful constru√≠da com **Flask** para servir previs√µes de modelos implantados, permitindo que aplica√ß√µes consumam os modelos com baixa lat√™ncia e alta disponibilidade.
- **Monitoramento e Escalabilidade**: Mecanismos para simular o monitoramento de modelos em produ√ß√£o e a capacidade de escalar deployments (`scale_deployment`) para lidar com cargas de trabalho vari√°veis, garantindo resili√™ncia e performance.
- **Automa√ß√£o Completa**: Demonstra√ß√£o de como automatizar o ciclo de vida do modelo, desde o registro at√© o deploy e undeploy, seguindo princ√≠pios de CI/CD.
- **C√≥digo Profissional**: Exemplos de c√≥digo bem estruturados, seguindo as melhores pr√°ticas da ind√∫stria, com foco em modularidade, reusabilidade e manutenibilidade.
- **Documenta√ß√£o Completa**: Cada componente da plataforma √© acompanhado de documenta√ß√£o detalhada, diagramas explicativos e casos de uso pr√°ticos.
- **Testes Inclu√≠dos**: M√≥dulos de c√≥digo validados atrav√©s de testes unit√°rios e de integra√ß√£o, garantindo a robustez e a confiabilidade das solu√ß√µes.

### üöÄ Benef√≠cios do MLOps em A√ß√£o

A implementa√ß√£o de pr√°ticas de MLOps traz uma s√©rie de benef√≠cios cruciais para o desenvolvimento e opera√ß√£o de modelos de ML em escala. Este projeto ilustra como esses benef√≠cios s√£o alcan√ßados:

1.  **Ciclo de Vida Acelerado:** A automa√ß√£o do registro, deployment e monitoramento de modelos acelera o tempo de lan√ßamento de novos modelos e atualiza√ß√µes.

2.  **Confiabilidade e Estabilidade:** Estrat√©gias de deployment como Blue/Green e Canary garantem que novas vers√µes de modelos sejam introduzidas com seguran√ßa, minimizando o impacto em caso de falhas.

3.  **Reprodutibilidade:** O versionamento de modelos e a gest√£o de metadados permitem a reprodu√ß√£o exata de deployments anteriores, essencial para auditorias e depura√ß√£o.

4.  **Colabora√ß√£o Aprimorada:** A plataforma fornece uma interface padronizada para cientistas de dados e engenheiros de ML interagirem com o ciclo de vida do modelo.

5.  **Monitoramento Cont√≠nuo:** Embora simulado, o framework prev√™ a integra√ß√£o de ferramentas de monitoramento para detectar problemas de performance e *drift* de dados/modelo, acionando a√ß√µes corretivas.

6.  **Governan√ßa e Conformidade:** O registro de modelos e o rastreamento de vers√µes fornecem a base para uma governan√ßa robusta e conformidade com regulamenta√ß√µes.

---

## üá¨üáß MLOps Model Deployment Platform

This repository presents a **complete platform for deploying and managing Machine Learning (ML) models in production**, following MLOps best practices. The focus is on automating the model lifecycle, from training and versioning to deployment, monitoring, and retraining, ensuring **scalability, reliability, and reproducibility** in production environments.

### üéØ Objective

The main objective of this project is to **provide a detailed guide and functional code examples** for ML engineers, data scientists, and architects looking to build or optimize their MLOps pipelines. It will cover fundamental concepts, tools, and technologies to create a robust model deployment platform, with an emphasis on **model versioning, advanced deployment strategies, and a real-time inference API**.

### ‚ú® Highlights

- **Model Versioning**: Implementation of a `ModelRegistry` that supports versioning (`ModelMetadata`), allowing the management of different model versions and their associated metadata.
- **Advanced Deployment Strategies**: Support for various deployment strategies, such as **Blue/Green** and **Canary Releases**, to ensure safe and controlled transitions of models in production, minimizing risks and downtime.
- **Real-time Inference API (Flask)**: A RESTful API built with **Flask** to serve predictions from deployed models, allowing applications to consume models with low latency and high availability.
- **Monitoring and Scalability**: Mechanisms to simulate monitoring of models in production and the ability to scale deployments (`scale_deployment`) to handle varying workloads, ensuring resilience and performance.
- **Full Automation**: Demonstration of how to automate the model lifecycle, from registration to deployment and undeployment, following CI/CD principles.
- **Professional Code**: Well-structured code examples, following industry best practices, with a focus on modularity, reusability, and maintainability.
- **Complete Documentation**: Each platform component is accompanied by detailed documentation, explanatory diagrams, and practical use cases.
- **Tests Included**: Code modules validated through unit and integration tests, ensuring the robustness and reliability of the solutions.

### üìä Visualization

![MLOps Deployment Architecture](diagrams/mlops_deployment_architecture.png)

*Diagrama ilustrativo da arquitetura da Plataforma de Deploy de Modelos MLOps, destacando os principais componentes e o fluxo de trabalho.*


---

## üõ†Ô∏è Tecnologias Utilizadas / Technologies Used

| Categoria         | Tecnologia      | Descri√ß√£o                                                                 |
| :---------------- | :-------------- | :------------------------------------------------------------------------ |
| **Linguagem**     | Python          | Linguagem principal para desenvolvimento da plataforma MLOps e API.       |
| **Framework Web** | Flask           | Utilizado para construir a API RESTful de infer√™ncia de modelos.          |
| **Cont√™ineres**   | Docker          | Para empacotar modelos e suas depend√™ncias, garantindo portabilidade.     |
| **Orquestra√ß√£o**  | Kubernetes      | (Conceitual) Para orquestra√ß√£o e gerenciamento de deployments em escala.  |
| **Versionamento** | MLflow          | (Conceitual) Para rastreamento de experimentos e registro de modelos.     |
| **Serializa√ß√£o**  | Pickle / JSON   | Para persist√™ncia de modelos e comunica√ß√£o da API.                        |
| **Testes**        | `unittest`      | Framework de testes padr√£o do Python para valida√ß√£o de funcionalidades.   |
| **Diagrama√ß√£o**   | Mermaid         | Para cria√ß√£o de diagramas de arquitetura e fluxo de trabalho no README.   |

---

## üìÅ Repository Structure

```
mlops-model-deployment-platform/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ model_deployment.py      # L√≥gica principal da plataforma de deployment
‚îÇ   ‚îî‚îÄ‚îÄ model_serving_api.py     # Implementa√ß√£o da API Flask para infer√™ncia
‚îú‚îÄ‚îÄ data/                        # Dados de exemplo e modelos pr√©-treinados
‚îú‚îÄ‚îÄ images/                      # Imagens e diagramas para o README e documenta√ß√£o
‚îú‚îÄ‚îÄ tests/                       # Testes unit√°rios e de integra√ß√£o
‚îú‚îÄ‚îÄ docs/                        # Documenta√ß√£o adicional, guias e whitepapers sobre MLOps
‚îú‚îÄ‚îÄ config/                      # Arquivos de configura√ß√£o (ex: para ambiente de deploy)
‚îú‚îÄ‚îÄ models/                      # Diret√≥rio para armazenar modelos versionados
‚îú‚îÄ‚îÄ requirements.txt             # Depend√™ncias Python
‚îî‚îÄ‚îÄ README.md                    # Este arquivo
```

---

## üöÄ Getting Started

Para come√ßar, clone o reposit√≥rio e explore os diret√≥rios `src/` e `docs/` para exemplos detalhados e instru√ß√µes de uso. Certifique-se de ter as depend√™ncias necess√°rias instaladas.

### Pr√©-requisitos

- Python 3.9+
- `pip` (gerenciador de pacotes Python)
- `scikit-learn` (para o modelo de exemplo)

### Instala√ß√£o

```bash
git clone https://github.com/GabrielDemetriosLafis/mlops-model-deployment-platform.git
cd mlops-model-deployment-platform

# Instalar depend√™ncias Python
pip install -r requirements.txt
```

### Exemplo de Uso Avan√ßado (Python)

O exemplo abaixo demonstra a inicializa√ß√£o da `DeploymentPlatform`, o registro de um modelo, a promo√ß√£o entre ambientes (staging/production), o deployment com estrat√©gias avan√ßadas e a intera√ß√£o com a API de infer√™ncia. Este c√≥digo ilustra o ciclo de vida completo de um modelo em um ambiente MLOps.

```python
from src.model_deployment import DeploymentPlatform, ModelMetadata, Model, DeploymentConfig, DeploymentStrategy
from src.model_serving_api import app as model_api_app # Importa o aplicativo Flask
import requests
import json
import threading
import time

# Exemplo de uso
if __name__ == "__main__":
    print("\n==================================================")
    print("Demonstra√ß√£o da Plataforma de Deploy de Modelos MLOps")
    print("==================================================")

    # --- 0. Treinar e Salvar um Modelo de Exemplo ---
    # Em um cen√°rio real, isso viria de um pipeline de treinamento.
    # Para este exemplo, vamos criar um modelo dummy.
    print("\n--- 0. Treinando e Salvando Modelo de Exemplo ---")
    try:
        from sklearn.linear_model import LogisticRegression
        import pickle
        import numpy as np

        # Criar um modelo dummy
        X_train = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])
        y_train = np.array([0, 0, 1, 1, 1])
        dummy_model = LogisticRegression()
        dummy_model.fit(X_train, y_train)

        # Salvar o modelo
        model_path = "./models/dummy_model_v1.pkl"
        with open(model_path, "wb") as f:
            pickle.dump(dummy_model, f)
        print(f"  Modelo dummy salvo em {model_path}")
    except ImportError:
        print("  Scikit-learn n√£o instalado. Pulando a cria√ß√£o do modelo dummy.")
        print("  Por favor, instale com: pip install scikit-learn")
        exit() # Sair se scikit-learn n√£o estiver dispon√≠vel

    # --- 1. Inicializar Plataforma de Deployment ---
    print("\n--- 1. Inicializando Plataforma de Deployment ---")
    platform = DeploymentPlatform("production-platform")
    
    # --- 2. Registrar Modelo ---
    print("\n--- 2. Registrando Modelo ---")
    metadata_v1 = ModelMetadata(
        name="customer-churn-predictor",
        version="1.0.0",
        framework="scikit-learn",
        author="data-science-team@company.com",
        description="Modelo para predi√ß√£o de churn de clientes (v1)",
        metrics={"accuracy": 0.92, "precision": 0.89, "recall": 0.91},
        tags=["classification", "churn", "production"],
        model_path="./models/dummy_model_v1.pkl"
    )
    model_v1 = Model(metadata_v1)
    platform.registry.register_model(model_v1)
    print(f"  Modelo {model_v1.metadata.name} v{model_v1.metadata.version} registrado.")

    # --- 3. Promover Modelo para Staging e Produ√ß√£o ---
    print("\n--- 3. Promovendo Modelo para Staging e Produ√ß√£o ---")
    model_v1.promote_to_staging()
    print(f"  Modelo v1 status: {model_v1.status.value}")
    model_v1.promote_to_production()
    print(f"  Modelo v1 status: {model_v1.status.value}")

    # --- 4. Iniciar API de Servi√ßo de Modelos (em thread separada) ---
    print("\n--- 4. Iniciando API de Servi√ßo de Modelos ---")
    # A API precisa ser executada em uma thread separada para n√£o bloquear o script principal
    api_thread = threading.Thread(target=lambda: model_api_app.run(port=5000, debug=False, use_reloader=False))
    api_thread.daemon = True # Permite que a thread seja encerrada quando o programa principal sair
    api_thread.start()
    time.sleep(2) # Dar um tempo para a API iniciar
    print("  API de servi√ßo de modelos iniciada em http://127.0.0.1:5000")

    # --- 5. Realizar Deployment (Blue/Green) ---
    print("\n--- 5. Realizando Deployment Blue/Green para v1.0.0 ---")
    config_v1 = DeploymentConfig(
        strategy=DeploymentStrategy.BLUE_GREEN,
        replicas=3,
        auto_scaling=True
    )
    platform.deploy_model(model_v1, config_v1)
    print(f"  Deployment de {model_v1.metadata.name} v{model_v1.metadata.version} iniciado com estrat√©gia {config_v1.strategy.value}.")
    time.sleep(1) # Simular tempo de deployment
    info_v1 = platform.get_deployment_info(model_v1.metadata.name, model_v1.metadata.version)
    if info_v1:
        print(f"  Status do Deployment v1: {info_v1.get("status")}")

    # --- 6. Realizar Previs√£o via API ---
    print("\n--- 6. Realizando Previs√£o com o Modelo Implantado (v1.0.0) ---")
    input_data = {"features": [[0.7, 10]]} # Exemplo de entrada para o modelo dummy
    try:
        response = requests.post("http://127.0.0.1:5000/predict/customer-churn-predictor/1.0.0", json=input_data)
        response.raise_for_status()
        prediction_result = response.json()
        print(f"  Resultado da previs√£o (v1.0.0): {prediction_result}")
    except requests.exceptions.ConnectionError:
        print("  ERRO: N√£o foi poss√≠vel conectar √† API Flask. Verifique se ela est√° rodando.")
    except Exception as e:
        print(f"  Erro ao consultar API para previs√£o: {e}")

    # --- 7. Registrar e Implantar uma Nova Vers√£o (v2.0.0) com Canary Release ---
    print("\n--- 7. Registrando e Implantando Nova Vers√£o (v2.0.0) com Canary Release ---")
    # Criar um modelo dummy v2
    model_path_v2 = "./models/dummy_model_v2.pkl"
    dummy_model_v2 = LogisticRegression()
    dummy_model_v2.fit(X_train, y_train) # Usando os mesmos dados para simplicidade
    with open(model_path_v2, "wb") as f:
        pickle.dump(dummy_model_v2, f)
    print(f"  Modelo dummy v2 salvo em {model_path_v2}")

    metadata_v2 = ModelMetadata(
        name="customer-churn-predictor",
        version="2.0.0",
        framework="scikit-learn",
        author="data-science-team@company.com",
        description="Modelo para predi√ß√£o de churn de clientes (v2 - melhorado)",
        metrics={"accuracy": 0.95, "precision": 0.93, "recall": 0.94},
        tags=["classification", "churn", "production"],
        model_path="./models/dummy_model_v2.pkl"
    )
    model_v2 = Model(metadata_v2)
    platform.registry.register_model(model_v2)
    model_v2.promote_to_production()

    config_v2 = DeploymentConfig(
        strategy=DeploymentStrategy.CANARY,
        replicas=1, # Iniciar com 1 r√©plica para canary
        auto_scaling=False,
        canary_traffic_percentage=10 # 10% do tr√°fego para a nova vers√£o
    )
    platform.deploy_model(model_v2, config_v2)
    print(f"  Deployment de {model_v2.metadata.name} v{model_v2.metadata.version} iniciado com estrat√©gia {config_v2.strategy.value}.")
    time.sleep(1) # Simular tempo de deployment
    info_v2 = platform.get_deployment_info(model_v2.metadata.name, model_v2.metadata.version)
    if info_v2:
        print(f"  Status do Deployment v2 (Canary): {info_v2.get("status")}")

    # --- 8. Escalar Deployment (para v1.0.0) ---
    print("\n--- 8. Escalando Deployment de v1.0.0 para 5 r√©plicas ---")
    platform.scale_deployment(model_v1.metadata.name, model_v1.metadata.version, 5)
    print(f"  Deployment de {model_v1.metadata.name} v{model_v1.metadata.version} escalado para 5 r√©plicas (simulado).")

    # --- 9. Desimplantar Modelo (v1.0.0) ---
    print("\n--- 9. Desimplantando Modelo v1.0.0 ---")
    platform.undeploy_model(model_v1.metadata.name, model_v1.metadata.version)
    info_v1_after_undeploy = platform.get_deployment_info(model_v1.metadata.name, model_v1.metadata.version)
    if not info_v1_after_undeploy:
        print(f"  Modelo {model_v1.metadata.name} v{model_v1.metadata.version} desimplantado com sucesso.")

    # --- 10. Desimplantar Modelo (v2.0.0) ---
    print("\n--- 10. Desimplantando Modelo v2.0.0 ---")
    platform.undeploy_model(model_v2.metadata.name, model_v2.metadata.version)
    info_v2_after_undeploy = platform.get_deployment_info(model_v2.metadata.name, model_v2.metadata.version)
    if not info_v2_after_undeploy:
        print(f"  Modelo {model_v2.metadata.name} v{model_v2.metadata.version} desimplantado com sucesso.")

    print("\n==================================================")
    print("Demonstra√ß√£o Conclu√≠da.")
    print("==================================================")
```

---

## ü§ù Contribui√ß√£o

Contribui√ß√µes s√£o bem-vindas! Sinta-se √† vontade para abrir issues, enviar pull requests ou sugerir melhorias. Por favor, siga as diretrizes de contribui√ß√£o.

---

## üìù Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

---

**Autor:** Gabriel Demetrios Lafis  \n**Ano:** 2025